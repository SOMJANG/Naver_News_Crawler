{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naver News Crawler\n",
    "\n",
    "#### 작성자 : 장동현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wd\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "def get_article_info(driver, crawl_date, press_list, title_list, link_list, date_list, \n",
    "                     more_news_base_url=None, more_news=False):\n",
    "    more_news_url_list = []\n",
    "    while True:    \n",
    "        page_html_source = driver.page_source\n",
    "        url_soup = BeautifulSoup(page_html_source, 'lxml')\n",
    "        \n",
    "        more_news_infos = url_soup.select('a.news_more')\n",
    "        \n",
    "        if more_news:\n",
    "            for more_news_info in more_news_infos:\n",
    "                more_news_url = f\"{more_news_base_url}{more_news_info.get('href')}\"\n",
    "\n",
    "                more_news_url_list.append(more_news_url)\n",
    "\n",
    "        article_infos = url_soup.select(\"div.news_area\")\n",
    "        \n",
    "        if not article_infos:\n",
    "            break\n",
    "\n",
    "        for article_info in article_infos:\n",
    "            press_info = article_info.select_one(\"div.info_group > a.info.press\")\n",
    "            \n",
    "            if press_info is None:\n",
    "                press_info = article_info.select_one(\"div.info_group > span.info.press\")\n",
    "            article = article_info.select_one(\"a.news_tit\")\n",
    "            \n",
    "            press = press_info.text.replace(\"언론사 선정\", \"\")\n",
    "            title = article.get('title')\n",
    "            link = article.get('href')\n",
    "\n",
    "            press_list.append(press)\n",
    "            title_list.append(title)\n",
    "            link_list.append(link)\n",
    "            date_list.append(crawl_date)\n",
    "\n",
    "        time.sleep(2.0)\n",
    "                      \n",
    "                      \n",
    "        next_button_status = url_soup.select_one(\"a.btn_next\").get(\"aria-disabled\")\n",
    "        \n",
    "        if next_button_status == 'true':\n",
    "            break\n",
    "        \n",
    "        time.sleep(1.0)\n",
    "        next_page_btn = driver.find_element_by_css_selector(\"a.btn_next\").click()      \n",
    "    \n",
    "    return press_list, title_list, link_list, more_news_url_list\n",
    "    \n",
    "    \n",
    "\n",
    "def get_naver_news_info_from_selenium(driver_path, keyword, save_path, target_date, ds_de, sort=0, remove_duplicate=False):\n",
    "    crawl_date = f\"{target_date[:4]}.{target_date[4:6]}.{target_date[6:]}\"\n",
    "    driver = wd.Chrome(driver_path)\n",
    "\n",
    "    encoded_keyword = urllib.parse.quote(keyword)\n",
    "    url = f\"https://search.naver.com/search.naver?where=news&query={encoded_keyword}&sm=tab_opt&sort={sort}&photo=0&field=0&pd=3&ds={ds_de}&de={ds_de}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom{target_date}to{target_date}&is_sug_officeid=0\"\n",
    "    \n",
    "    more_news_base_url = \"https://search.naver.com/search.naver\"\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    press_list, title_list, link_list, date_list, more_news_url_list = [], [], [], [], []\n",
    "    \n",
    "    press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n",
    "                                                                             crawl_date=crawl_date, \n",
    "                                                                             press_list=press_list, \n",
    "                                                                             title_list=title_list, \n",
    "                                                                             link_list=link_list,\n",
    "                                                                             date_list=date_list,\n",
    "                                                                             more_news_base_url=more_news_base_url,\n",
    "                                                                             more_news=True)\n",
    "    driver.close()\n",
    "    \n",
    "    if len(more_news_url_list) > 0:\n",
    "        print(len(more_news_url_list))\n",
    "        more_news_url_list = list(set(more_news_url_list))\n",
    "        print(f\"->{len(more_news_url_list)}\")\n",
    "        for more_news_url in more_news_url_list:\n",
    "            driver = wd.Chrome(\"./chromedriver_96\")\n",
    "            driver.get(more_news_url)\n",
    "            \n",
    "            press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n",
    "                                                                             crawl_date=crawl_date, \n",
    "                                                                             press_list=press_list, \n",
    "                                                                             title_list=title_list, \n",
    "                                                                             link_list=link_list,\n",
    "                                                                             date_list=date_list)\n",
    "            driver.close()\n",
    "    article_df = pd.DataFrame({\"날짜\": date_list, \"언론사\": press_list, \"제목\": title_list, \"링크\": link_list})\n",
    "    \n",
    "    print(f\"extract article num : {len(article_df)}\")\n",
    "    if remove_duplicate:\n",
    "        article_df = article_df.drop_duplicates(['링크'], keep='first')\n",
    "        print(f\"after remove duplicate -> {len(article_df)}\")\n",
    "    \n",
    "    article_df.to_excel(save_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crawl_news_data(driver_path, keyword, year, month, start_day, end_day, save_path_dir):\n",
    "    for day in tqdm(range(start_day, end_day+1)):\n",
    "        date_time_obj = datetime(year=year, month=month, day=day)\n",
    "        target_date = date_time_obj.strftime(\"%Y%m%d\")\n",
    "        ds_de = date_time_obj.strftime(\"%Y.%m.%d\")\n",
    "\n",
    "        get_naver_news_info_from_selenium(driver_path=driver_path, keyword=keyword, \n",
    "                                          save_path=f\"{save_path_dir}/{keyword}/{target_date}_{keyword}_.xlsx\", target_date=target_date, ds_de=ds_de, remove_duplicate=False)\n",
    "        \n",
    "def bulk_keyword_crawler(driver_path, keywords, year, month, start_day, end_day, save_path_dir):\n",
    "    for keyword in keywords:\n",
    "        print(f\"start keyword - {keyword} crawling ...\")\n",
    "        crawl_news_data(driver_path=driver_path, keyword=keyword, year=2022, month=1, start_day=1, end_day=1, save_path_dir=save_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용 예시\n",
    "\n",
    "- 기간 : 2022년 1월 1일 ~ 2022년 1월 5일\n",
    "- 키워드 : '토스', '야놀자', '당근마켓', '아프리카tv', '온플법', '매치그룹'\n",
    "- 경로 : \"./extract_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year, month = 2022, 1\n",
    "start_day, end_day = 1, 1\n",
    "keywords = ['토스', '야놀자', '당근마켓', '아프리카tv', '온플법', '매치그룹']\n",
    "save_path_dir = \"추출 파일 저장 최상위 경로\"\n",
    "driver_path = \"크롬드라이버 파일 경로\"\n",
    "\n",
    "bulk_keyword_crawler(driver_path=driver_path, keywords=keywords, year=year, month=month, \n",
    "                     start_day=start_day, end_day=end_day, save_path_dir=save_path_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_python",
   "language": "python",
   "name": "test_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
